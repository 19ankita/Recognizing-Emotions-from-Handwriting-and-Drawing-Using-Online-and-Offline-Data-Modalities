---

# Transfer Learning Regression

This module implements multi-output regression using transfer learning for predicting DASS-21 emotional scores (Depression, Anxiety, Stress, Total) from handwriting and drawing images combined with pseudo-dynamic features.

The approach integrates:

* Image-based features extracted using a pretrained ResNet-18 backbone
* Pseudo-dynamic handwriting features derived from offline images
* Multi-output regression with bounded predictions

---

## ğŸ“Œ Overview

The model predicts four continuous emotional scores:

* Depression
* Anxiety
* Stress
* Total DASS

Predictions are normalized to ([0,1]) during training and rescaled to original DASS ranges during evaluation.

The architecture combines:

* Image embeddings (ResNet-18 pretrained on ImageNet)
* A small MLP for pseudo-dynamic features
* Feature fusion via concatenation
* A linear regression head with sigmoid activation

---

## ğŸ— Model Architecture

```
Image (224Ã—224 RGB)
        â†“
ResNet-18 Backbone (pretrained)
        â†“
512-D Image Features

Pseudo-Dynamic Features (5-D)
        â†“
MLP â†’ 32-D Embedding

Concatenation (512 + 32)
        â†“
Linear Regression Head (4 outputs)
        â†“
Sigmoid Activation
```

Backbone freezing is optional via CLI flag.

---

## ğŸ“‚ Directory Structure

```
transfer_learning_regression/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ utils/
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ best_model_*.pth
â”‚   â”œâ”€â”€ training_metrics.csv
â”‚   â”œâ”€â”€ best_epoch_summary.csv
â”‚
â”œâ”€â”€ train.py
â””â”€â”€ README.md
```

---

## ğŸ“Š Dataset Requirements

The dataset should be structured as:

```
task_root/
â”‚
â”œâ”€â”€ CDT/
â”‚   â”œâ”€â”€ class_folder/
â”‚   â”‚   â”œâ”€â”€ sample1.png
â”‚   â”‚   â”œâ”€â”€ sample2.png
â”‚
â”œâ”€â”€ House/
â”œâ”€â”€ Pentagon/
â”œâ”€â”€ Cursive_writing/
â”œâ”€â”€ Words/
```

Additionally, a CSV file must contain DASS scores:

```
id,depression,anxiety,stress,total
sample1,12,8,14,34
sample2,5,3,6,14
...
```

---

## âš™ï¸ Installation

Create environment:

```bash
conda create -n handwriting_env python=3.10
conda activate handwriting_env
```

Install dependencies:

```bash
pip install torch torchvision albumentations scikit-learn numpy pandas matplotlib tqdm
```

---

## ğŸš€ Training

### Basic Run

```bash
python train.py \
    --task CDT \
    --task_dir path/to/dataset \
    --label_csv path/to/DASS_scores.csv \
    --epochs 20
```

### Train on All Tasks

```bash
python train.py \
    --task all \
    --task_dir path/to/dataset \
    --label_csv path/to/DASS_scores.csv
```

---

## ğŸ§ª CLI Arguments

| Argument            | Description                                                            |
| ------------------- | ---------------------------------------------------------------------- |
| `--task`            | Task name (e.g., CDT, House, Pentagon, Cursive_writing, Words, or all) |
| `--task_dir`        | Root directory of dataset                                              |
| `--label_csv`       | Path to DASS label CSV                                                 |
| `--epochs`          | Number of training epochs (default: 20)                                |
| `--lr`              | Learning rate (default: 1e-3)                                          |
| `--freeze_backbone` | Freeze ResNet backbone                                                 |
| `--batch_size`      | Batch size (default: 32)                                               |
| `--img_size`        | Input image size (default: 224)                                        |
| `--val_ratio`       | Validation split ratio (default: 0.2)                                  |
| `--num_workers`     | DataLoader workers (default: 2)                                        |

---

## ğŸ“ˆ Training Strategy

* Loss: Mean Squared Error (MSE)
* Optimizer: AdamW (weight decay = 1e-4)
* Learning Rate Schedule:

  * 2-epoch linear warmup
  * Cosine decay
* Mixed Precision (AMP) enabled on GPU
* Best model selected based on validation (R^2)

---

## ğŸ“Š Evaluation Metrics

For each epoch:

* Train MSE
* Validation MSE
* Validation RMSE
* Validation (R^2)
* Per-dimension RMSE & (R^2)

Best epoch summary is saved to:

```
outputs/best_epoch_summary.csv
```

---

## ğŸ’¾ Outputs

* `best_model_<task>_regression.pth`
* `training_metrics.csv`
* Training curves (RMSE and RÂ² plots)
* Best epoch summary

---

## ğŸ§  Key Design Decisions

* Sigmoid output to enforce bounded predictions
* Label normalization for stable training
* Feature fusion to combine spatial and pseudo-temporal cues
* Optional backbone freezing to evaluate transfer learning strategies

---

## ğŸ”¬ Research Purpose

This module is part of a broader study investigating:

* Emotional state recognition from handwriting and drawing
* Comparison between structured drawing and expressive writing tasks
* Online vs offline feature integration
* Transfer learning effectiveness in behavioral modeling

---

