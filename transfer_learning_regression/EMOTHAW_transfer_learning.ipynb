{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "392d86e9"
      },
      "source": [
        "!rm -rf /content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd4a8371",
        "outputId": "3094276f-40a9-4846-f46b-3944dea81af7"
      },
      "source": [
        "!git clone https://github.com/19ankita/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities'...\n",
            "remote: Enumerating objects: 2024, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 2024 (delta 74), reused 75 (delta 39), pack-reused 1906 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2024/2024), 167.97 MiB | 21.36 MiB/s, done.\n",
            "Resolving deltas: 100% (380/380), done.\n",
            "Updating files: 100% (4570/4570), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4vqlIvNmxZI",
        "outputId": "75b3337a-ca97-4886-9c0b-4324d3fcd462"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add PYTHONPATH\n",
        "import os\n",
        "os.environ[\"PYTHONPATH\"] = \"/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning\""
      ],
      "metadata": {
        "id": "PZIL1VNSQZ_R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==1.3.0\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "Ss_zuQygjMmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!python /content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/run_train.py --config configs/default.yaml"
      ],
      "metadata": {
        "id": "1zBEhELFQd5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/utils/plot_training.py --history outputs/history.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvqgueFaonEe",
        "outputId": "103f8d3f-39e6-42c7-9111-f2bf74b42a43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot → outputs/training_plot.png\n",
            "Saved high-quality PDF → outputs/training_plot.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/utils/plot_all.py --history outputs/history.json --model outputs/best_model.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqFH6qsgqH3O",
        "outputId": "ed4fea14-e21d-4893-eaee-e6fb38deab88"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/utils/plot_all.py\", line 192, in <module>\n",
            "    plot_class_accuracy(config, model_path)\n",
            "  File \"/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/utils/plot_all.py\", line 46, in plot_class_accuracy\n",
            "    cfg = yaml.safe_load(open(config_path, \"r\"))\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'configs/default.yaml'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/utils/visualize_aug.py --config configs/default.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvwUza2kxtCD",
        "outputId": "c61fcd35-faac-4f4a-fb35-99768cc58d46"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/utils/visualize_aug.py\", line 138, in <module>\n",
            "    visualize_augmentations(args.config)\n",
            "  File \"/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/utils/visualize_aug.py\", line 86, in visualize_augmentations\n",
            "    cfg = yaml.safe_load(open(config_path, \"r\"))\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'configs/default.yaml'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjsm4cFyA-G4",
        "outputId": "2c3bd306-0129-40fb-f1ef-6fcd76b3d6c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grad-cam in /usr/local/lib/python3.12/dist-packages (1.5.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from grad-cam) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from grad-cam) (11.3.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from grad-cam) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from grad-cam) (0.24.0+cu126)\n",
            "Requirement already satisfied: ttach in /usr/local/lib/python3.12/dist-packages (from grad-cam) (0.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from grad-cam) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from grad-cam) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from grad-cam) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.7.1->grad-cam) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->grad-cam) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->grad-cam) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.7.1->grad-cam) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " For CLI"
      ],
      "metadata": {
        "id": "D9GQLyidIjwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_train.py --task all --model resnet18 --task_dir data/emothaw_tasks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHxkxZ3eIfwB",
        "outputId": "4ed874fd-341d-473a-e9bc-7f935472cdb8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device → cuda\n",
            "/usr/local/lib/python3.12/dist-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/src/dataset.py:25: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
            "  A.ElasticTransform(\n",
            "/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/src/dataset.py:35: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=2,\n",
            "Loading ALL tasks...\n",
            " : data/emothaw_tasks/cdt\n",
            " : data/emothaw_tasks/cursive_writing\n",
            " : data/emothaw_tasks/house\n",
            " : data/emothaw_tasks/pentagon\n",
            " : data/emothaw_tasks/words\n",
            "\n",
            ">>> Building model: resnet18\n",
            "\n",
            "==== Epoch 1/20 ====\n",
            "Training: 100% 49/49 [06:44<00:00,  8.26s/it]\n",
            "Validating: 100% 13/13 [01:13<00:00,  5.63s/it]\n",
            "Train Loss: 1.2165 | Train Acc: 0.3357\n",
            "Val Loss:   1.1153 | Val Acc:   0.3189\n",
            "Current LR: 0.001\n",
            "Saved checkpoint: outputs/best_model_all_resnet18.pth\n",
            "Saved new BEST model : best_model_all_resnet18.pth\n",
            "Saved new BEST model\n",
            "Exception ignored in: <function BaseCAM.__del__ at 0x7ba554259a80>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_grad_cam/base_cam.py\", line 212, in __del__\n",
            "    self.activations_and_grads.release()\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/run_train.py\", line 294, in <module>\n",
            "    run_train(args)\n",
            "  File \"/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/run_train.py\", line 250, in run_train\n",
            "    generate_gradcam(\n",
            "  File \"/content/Recognizing-Emotions-from-Handwriting-and-Drawing-Using-Online-and-Offline-Data-Modalities/transfer_learning/run_train.py\", line 48, in generate_gradcam\n",
            "    cam = GradCAM(model=model, target_layers=[target_layer], use_cuda=True)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: GradCAM.__init__() got an unexpected keyword argument 'use_cuda'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6fGIqU4DAa_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}